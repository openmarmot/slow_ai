# slow_ai
Local LLM framework optimized for slow response times

### project status 
- just getting started building components.
- things will probably not work
- read the change_log.txt for details

### usage
- launch the program with run.sh