# slow_ai
Local LLM framework optimized for slow response times

## project status 
- just getting started. nothing works yet
